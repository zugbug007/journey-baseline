---
title: ""
output:
  html_document: 
    theme: flatly
    toc: true
    toc_float: true
    css: styles.css
    self_contained: true
params:
  company_id: "thenat3"
  rsid: "nationaltrustmainsiteprod"
  google_account: "alan.millington@nationaltrust.org.uk"
  alt_google_account: "alan.d.millington@gmail.com"
editor_options: 
  chunk_output_type: inline
---

```{r load_workspace_from_file, echo=FALSE, message=FALSE, warning=FALSE}
#load("output/baseline-workspace.RData")

# Blue = "#406882"
# Red = "#f05454"
# Purple = "#824068"
# Green ="#688240"
# Dark Blue = "#4d4082"

```

```{r setup_libraries, include=FALSE, warning =FALSE, message=FALSE}
# Capturing the start time -- the final output will include how long
# it took for the process to run.
monitorStartTime_baseline <- Sys.time()

rsid = "nationaltrustmainsiteprod"

# Check for packages needed and then load the packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse,
               tidyquant,
               zoo,
               CausalImpact,
               ggplot2,
               ggalt,
               lubridate,
               forecast,
               plotly,
               patchwork,
               gridExtra,
               htmltools,
               GGally,
               rpivotTable,
               plotly,
               adobeanalyticsr,
               googlesheets4,
               scales,
               htmltools,  
               knitr,
               RColorBrewer,
               anomalize,
               grafify,
               flextable,
               kableExtra,
               RColorBrewer,
               forcats,
               changepoint,
               searchConsoleR,
               prophet,
               vistime,
               sparkline)

gs4_auth(email = params$google_account)
scr_auth(email = params$alt_google_account)
# Test Token has been refreshed and is up to date.
#library(adobeanalyticsr)
#aw_token()
#aw_auth()
# Check Adobe API Token Access Now
#aw_calculatedmetrics <- aw_get_calculatedmetrics(rsid = rsid)
#aw_segments <- aw_get_segments(rsid = rsid, limit = 3000, page = 2)
#rm(aw_segments)

# Test GSheets Connections
gsheet = "https://docs.google.com/spreadsheets/d/18yWHyyWGSxSYc35lIAYvWPBFxZNB04WHnDG0_MmyHEo/edit#gid=0"
journey_segments_googlesheet <- read_sheet(gsheet, range = "journey")

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                 Setup Date Ranges and Common Date Variables              ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# pre dates will be hard coded when new site launches
pre_start_date <- Sys.Date() - 180 #180
pre_end_date <- Sys.Date() - 91  #91
pre_end_date_7 <- pre_end_date - 7
pre_date_range = c(as.Date(pre_start_date), as.Date(pre_end_date))

# Post Launch Date Prep, Adjust date after launch date is known and ~90 days back.
post_start_date <- Sys.Date() - 90 # post start date will set to launch date of the new site
post_end_date <- Sys.Date() - 1
post_date_range = c(as.Date(post_start_date), as.Date(post_end_date))

# Post Launch Date Improvement Monitoring Dates. Use start dates below and post_end_date for comparison.
post_start_date_3 <- post_end_date - 3
post_start_date_7 <- post_end_date - 7
post_start_date_14 <- post_end_date - 14
post_start_date_30 <- post_end_date - 30
post_start_date_60 <- post_end_date - 60

# Last.. 7 Days, month Etc.
# Setup Dates for Last Month
last_month_start <- format(Sys.Date() - 30, '%Y-%m-01')
last_month_end <- as.character(as.Date(format(Sys.Date(), '%Y-%m-01')) - 1)

# Create a rolling window starting two weeks back and plus 7 days.
start_14_days_ago_days <- Sys.Date() - 15
end_7_days_ago <- Sys.Date() - 8
two_weeks_ago <- c(start_14_days_ago_days, end_7_days_ago)

# Get Date Starting on a Sunday Two Weeks Ago
start_14_sun_start <- floor_date(as.Date(start_14_days_ago_days, "%m/%d/%Y"), unit="week")
end_14_sun_end <- as.Date(start_14_sun_start) + 6

#Get Date Starting on a Sunday 1 Week Ago
start_7_sun_start <- floor_date(as.Date(end_7_days_ago, "%m/%d/%Y"), unit="week")
end_7_sun_end <- as.Date(start_7_sun_start) + 6
last_7_full_week <- c(start_7_sun_start, end_7_sun_end)

# Last two weeks
last_two_full_weeks <- c(two_weeks_ago[1], last_7_full_week[2])

# Previous Week
previous_week_7 <- lubridate::floor_date(Sys.Date(), "week")
previous_week_7_end <- previous_week_7
previous_week_7_start <- previous_week_7 - 7
previous_week <- c(previous_week_7_start, previous_week_7_end)

website <- "https://www.nationaltrust.org.uk"
download_dimensions <- c('query')
type <- c('web')
  
```

```{r get_data, include=FALSE, warning=FALSE, message=FALSE, cache=FALSE}
# Update the Data

source("code/get_g_sheets.R")
source("code/get_functions.R")
#source("code/get_journey_data.R") #Log out of VPN, very slow to pull data.

journey_data <- readRDS("output/df_journey_data.rds")
anomaly_data <- readRDS("output/df_anomaly_data.rds")

source("code/post_processing.R")
source("code/build_plots.R")
source("code/get_forecasts.R")

  
```


# Summary
This tool builds the baseline for many journeys across the website.  


## Timeline of Activity  

```{r child = "code/00_timeline.Rmd"}
```

## Summary of Website Journeys

```{r child = "code/01_summary.Rmd"}
```

## Journeys in Detail

```{r child = "code/02_journey_detail.Rmd"}
```


## Commercial Analysis

```{r child = "code/06_funnels.Rmd"}

```


## Anomaly Plots By Journey

```{r child = "code/03_anomalys_detail.Rmd"}

```


```{r runtime, echo=FALSE}
monitorEndTime_baseline <- Sys.time()
# Write out to the console how long it took for the entire process to run.
lastrunTime_baseline <- paste0("This process took ",monitorEndTime_baseline - monitorStartTime_baseline," minutes to run.",sep=" ")
lastrunTime_baseline
```

Last Run Date: '`r format(Sys.time(), "%d %B, %Y")`'

```{r save_workspace_image, echo=FALSE}
save.image(file = "output/baseline-workspace.RData")
```

