---
title: ""
output:
  html_document: 
    theme: flatly
    toc: true
    toc_float: true
    css: styles.css
    self_contained: true
    includes:
        after_body: footer.html
params:
  company_id: "thenat3"
  rsid: "nationaltrustmainsiteprod"
  google_account: "alan.millington@nationaltrust.org.uk"
  alt_google_account: "alan.d.millington@gmail.com"
editor_options: 
  chunk_output_type: inline
---

```{r load_workspace_from_file, echo=FALSE, message=FALSE, warning=FALSE}
#load("output/baseline-workspace.RData")

# Blue = "#406882"
# Red = "#f05454"
# Purple = "#824068"
# Green ="#688240"
# Dark Blue = "#4d4082"

```

```{r setup_libraries, include=FALSE, warning =FALSE, message=FALSE}

update_data <- FALSE

# Capturing the start time -- the final output will include how long
# it took for the process to run.
monitorStartTime_baseline <- Sys.time()

rsid = "nationaltrustmainsiteprod"

# Check for packages needed and then load the packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse,
               tidyquant,
               zoo,
               CausalImpact,
               ggplot2,
               ggalt,
               lubridate,
               forecast,
               plotly,
               patchwork,
               gridExtra,
               htmltools,
               GGally,
               rpivotTable,
               plotly,
               adobeanalyticsr,
               googlesheets4,
               scales,
               htmltools,  
               knitr,
               RColorBrewer,
               anomalize,
               grafify,
               flextable,
               kableExtra,
               RColorBrewer,
               forcats,
               changepoint,
               searchConsoleR,
               prophet,
               vistime,
               DT,
               sparkline)

gs4_auth(email = params$google_account)
scr_auth(email = params$alt_google_account)
# Test Token has been refreshed and is up to date.
#library(adobeanalyticsr)
#aw_token()
#aw_auth()
# Check Adobe API Token Access Now
#aw_calculatedmetrics <- aw_get_calculatedmetrics(rsid = rsid)
aw_segments <- aw_get_segments(rsid = rsid, limit = 3000, page = 2)
#rm(aw_segments)

# Test GSheets Connections
gsheet = "https://docs.google.com/spreadsheets/d/18yWHyyWGSxSYc35lIAYvWPBFxZNB04WHnDG0_MmyHEo/edit#gid=0"
journey_segments_googlesheet <- read_sheet(gsheet, range = "journey")

# Cutoff for total instances (or occurrences) below which will flag as "Minimal Data"
min_instances <- 100

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                 Setup Date Ranges and Common Date Variables              ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# pre dates will be hard coded when new site launches
pre_start_date <- Sys.Date() - 180 #180
pre_end_date <- Sys.Date() - 91  #91
pre_end_date_7 <- pre_end_date - 7
pre_end_date_30 <- pre_end_date - 30
pre_date_range = c(as.Date(pre_start_date), as.Date(pre_end_date))

# Post Launch Date Prep, Adjust date after launch date is known and ~90 days back.
post_start_date <- Sys.Date() - 90 # post start date will set to launch date of the new site
post_end_date <- Sys.Date() - 1
post_date_range = c(as.Date(post_start_date), as.Date(post_end_date))

# Post Launch Date Improvement Monitoring Dates. Use start dates below and post_end_date for comparison.
post_start_date_3 <- post_end_date - 3
post_start_date_7 <- post_end_date - 7
post_start_date_14 <- post_end_date - 14
post_start_date_30 <- post_end_date - 30
post_start_date_60 <- post_end_date - 60

# Last.. 7 Days, month Etc.
# Setup Dates for Last Month
last_month_start <- format(Sys.Date() - 30, '%Y-%m-01')
last_month_end <- as.character(as.Date(format(Sys.Date(), '%Y-%m-01')) - 1)

# Create a rolling window starting two weeks back and plus 7 days.
start_14_days_ago_days <- Sys.Date() - 15
end_7_days_ago <- Sys.Date() - 8
two_weeks_ago <- c(start_14_days_ago_days, end_7_days_ago)

# Get Date Starting on a Sunday Two Weeks Ago
start_14_sun_start <- floor_date(as.Date(start_14_days_ago_days, "%m/%d/%Y"), unit="week")
end_14_sun_end <- as.Date(start_14_sun_start) + 6

#Get Date Starting on a Sunday 1 Week Ago
start_7_sun_start <- floor_date(as.Date(end_7_days_ago, "%m/%d/%Y"), unit="week")
end_7_sun_end <- as.Date(start_7_sun_start) + 6
last_7_full_week <- c(start_7_sun_start, end_7_sun_end)

# Last two weeks
last_two_full_weeks <- c(two_weeks_ago[1], last_7_full_week[2])

# Previous Week
previous_week_7 <- lubridate::floor_date(Sys.Date(), "week")
previous_week_7_end <- previous_week_7
previous_week_7_start <- previous_week_7 - 7
previous_week <- c(previous_week_7_start, previous_week_7_end)

website <- "https://www.nationaltrust.org.uk"
download_dimensions <- c('query')
type <- c('web')

df_metrics <- aw_get_metrics(
    company_id = Sys.getenv("AW_COMPANY_ID"), 
    rsid = Sys.getenv("AW_REPORTSUITE_ID"))
      if("description" %in% colnames(df_metrics) == FALSE){
    df_metrics$description <- ""
    }

```

```{r get_data, include=FALSE, warning=FALSE, message=FALSE, cache=FALSE}
# Update the Data
source("code/get_g_sheets.R")
source("code/get_functions.R")

if(update_data == TRUE) {
  print("Running Data Load")
  source("code/get_journey_data.R") #Log out of VPN, very slow to pull data.
  source("code/get_events_data.R")
} else {
  print("Loading local Files")
  journey_data <- readRDS("output/df_journey_data.rds")
  anomaly_data <- readRDS("output/df_anomaly_data.rds")
  df_events <- readRDS("output/df_events.rds")
  df_events_daily <- readRDS("output/df_events_daily.rds")
}

source("code/post_processing.R")
source("code/build_plots.R")

```


# Summary
This tool builds the baseline for many journeys across the website.  


## Launch Timeline 

```{r child = "code/00_timeline.Rmd"}
```

## Summary of Website Journeys

```{r child = "code/01_summary.Rmd"}
```

## Journeys in Detail

```{r child = "code/02_journey_detail.Rmd"}
```


## Commercial Analysis

```{r child = "code/06_funnels.Rmd"}

```


## Journey Trends

```{r child = "code/03_anomalys_detail.Rmd"}

```


## Search Analysis

```{r child = "code/04_search.Rmd"}

```


## Events

```{r child = "code/07_events.Rmd"}

```


## Forecasts

```{r child = "code/08_forecasts.Rmd"}

```



```{r runtime, echo=FALSE}
monitorEndTime_baseline <- Sys.time()
# Write out to the console how long it took for the entire process to run.
last_run <- as.numeric(monitorEndTime_baseline - monitorStartTime_baseline, units = "mins")
last_run <- round(last_run)
lastrunTime_baseline <- paste0("This process took ",last_run," minutes to build this analysis.",sep=" ")
```

Last Run Date: '`r format(Sys.time(), "%d %B, %Y")`'  
`r lastrunTime_baseline`

```{r save_workspace_image, echo=FALSE, message=FALSE, warning=FALSE}
save.image(file = "output/baseline-workspace.RData")

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                         Outputs to the Google Sheet                      ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#write_sheet(journey_data, gsheet, sheet ="Journey_data")
#write_sheet(anomaly_data, gsheet, sheet ="Anomaly_data")
#write_sheet(compare_to_day, gsheet, sheet ="compare_to_day")
#write_sheet(baseline, gsheet, sheet = "Baseline")
```

